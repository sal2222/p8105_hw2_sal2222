p8105\_hw2\_sal2222
================
Stephen Lewandowski
October 4, 2018

-   [Problem 1](#problem-1)
-   [Problem 2](#problem-2)
-   [Problem 3](#problem-3)

Problem 1
=========

First, I will read and clean the NYC Transit data.

``` r
nyc_subway_data <- read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, 
         entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE)) 
 
nyc_subway_data
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu~ route1 route2
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr> 
    ##  1 4 Av~ 25th St                  40.7            -74.0 R      <NA>  
    ##  2 4 Av~ 25th St                  40.7            -74.0 R      <NA>  
    ##  3 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  4 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  5 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  6 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  7 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  8 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  9 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ## 10 4 Av~ 53rd St                  40.6            -74.0 R      <NA>  
    ## # ... with 1,858 more rows, and 13 more variables: route3 <chr>,
    ## #   route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>, route8 <int>,
    ## #   route9 <int>, route10 <int>, route11 <int>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

This datase contains information related to each entrance and exit for each subway station in New York City, including the subway line, station name, location grid coordinates, routes served, entrance type, and ADA compliance status. My data cleaning steps so far have been to standardize variable names in "snake\_case", select and retain my variables of interest, and to recode the entry variable from a character class with "YES" or "NO" values to a logical class with "TRUE" or "FALSE" values. My resulting dataset has **1868 rows** and **19 columns**. These data are **not tidy** at this stage. The multiple columns for route numbers (routes 1 through 11) represent values themselves rather than a variable name.

I will answer specific questions using these data.

*How many distinct stations are there?*

There are **465** distinct stations, identified by both line and station name.

*How many stations are ADA compliant?*

``` r
nyc_subway_data %>% 
  filter(ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 84

Of the 465 distinct stations, **84** have at least one ADA compliant entrance or exit.

*What proportion of station entrances / exits without vending allow entrance?*

``` r
{
  nyc_subway_data %>% 
  filter(vending == "NO") %>%
  filter(entry == TRUE) %>%  
  nrow()
} /
{
  nyc_subway_data %>% 
  filter(vending == "NO") %>%
  nrow()
}
```

    ## [1] 0.3770492

**0.37.7** (37.7%) of station entrances / exits without vending allow entrance. There are 183 entrances / exits without vending, and 69 of these allow entry.

I will now reformat the data so that route number and route name are distinct variables.

``` r
nyc_subway_data <- nyc_subway_data %>% 
  gather(key = route_number, value = route_name, route1:route11) 

nyc_subway_data
```

    ## # A tibble: 20,548 x 10
    ##    line  station_name station_latitude station_longitu~ entry vending
    ##    <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  
    ##  1 4 Av~ 25th St                  40.7            -74.0 TRUE  YES    
    ##  2 4 Av~ 25th St                  40.7            -74.0 TRUE  YES    
    ##  3 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ##  4 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ##  5 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ##  6 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ##  7 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ##  8 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ##  9 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ## 10 4 Av~ 53rd St                  40.6            -74.0 TRUE  YES    
    ## # ... with 20,538 more rows, and 4 more variables: entrance_type <chr>,
    ## #   ada <lgl>, route_number <chr>, route_name <chr>

*How many distinct stations serve the A train?*

``` r
nyc_subway_data %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 60

**60** distinct stations serve the A train.

*How many are ADA compliant?*

``` r
nyc_subway_data %>% 
  filter(ada == TRUE) %>%  
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 17

Of the 60 stations that serve the A train, **17** have at least one ADA compliant entry or exit.

Problem 2
=========

I will read and clean data from Mr. Trash Wheel in Baltimore Harbor.

``` r
trash_wheel <- read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
               sheet = "Mr. Trash Wheel", range =  cell_cols("A:N"), 
               col_names = TRUE, trim_ws = TRUE, skip = 1) %>% 
  janitor::clean_names() %>% 
  rename(dumpster_number = dumpster) %>% 
  filter(!is.na(dumpster_number)) %>% 
  filter(!(month == "Grand Total")) %>% 
  mutate(sports_balls = round(sports_balls, 0)) %>% 
  mutate(sports_balls = as.integer(sports_balls))

trash_wheel
```

    ## # A tibble: 215 x 14
    ##    dumpster_number month  year date                weight_tons
    ##              <dbl> <chr> <dbl> <dttm>                    <dbl>
    ##  1               1 May    2014 2014-05-16 00:00:00        4.31
    ##  2               2 May    2014 2014-05-16 00:00:00        2.74
    ##  3               3 May    2014 2014-05-16 00:00:00        3.45
    ##  4               4 May    2014 2014-05-17 00:00:00        3.1 
    ##  5               5 May    2014 2014-05-17 00:00:00        4.06
    ##  6               6 May    2014 2014-05-20 00:00:00        2.71
    ##  7               7 May    2014 2014-05-21 00:00:00        1.91
    ##  8               8 May    2014 2014-05-28 00:00:00        3.7 
    ##  9               9 June   2014 2014-06-05 00:00:00        2.52
    ## 10              10 June   2014 2014-06-11 00:00:00        3.76
    ## # ... with 205 more rows, and 9 more variables: volume_cubic_yards <dbl>,
    ## #   plastic_bottles <dbl>, polystyrene <dbl>, cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>

Next, I will read, clean, and combine precipitation data for 2016 and 2017.

``` r
precip_2017 <- read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
               sheet = "2017 Precipitation", range =  "A2:B14", 
               col_names = TRUE, trim_ws = TRUE) %>% 
  janitor::clean_names() %>%
  rename(total_precip_inches = total) %>% 
  filter(!is.na(total_precip_inches)) %>% 
  mutate(year = 2017) %>% 
  select(month, year, total_precip_inches)

precip_2017
```

    ## # A tibble: 8 x 3
    ##   month  year total_precip_inches
    ##   <dbl> <dbl>               <dbl>
    ## 1     1  2017                2.34
    ## 2     2  2017                1.46
    ## 3     3  2017                3.57
    ## 4     4  2017                3.99
    ## 5     5  2017                5.64
    ## 6     6  2017                1.4 
    ## 7     7  2017                7.09
    ## 8     8  2017                4.44

``` r
precip_2016 <- read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
               sheet = "2016 Precipitation", range =  "A2:B14", 
               col_names = TRUE, trim_ws = TRUE) %>% 
  janitor::clean_names() %>%
  rename(total_precip_inches = total) %>% 
  filter(!is.na(total_precip_inches)) %>% 
  mutate(year = 2016) %>% 
  select(month, year, total_precip_inches)

precip_2016
```

    ## # A tibble: 12 x 3
    ##    month  year total_precip_inches
    ##    <dbl> <dbl>               <dbl>
    ##  1     1  2016                3.23
    ##  2     2  2016                5.32
    ##  3     3  2016                2.24
    ##  4     4  2016                1.78
    ##  5     5  2016                5.19
    ##  6     6  2016                3.2 
    ##  7     7  2016                6.09
    ##  8     8  2016                3.96
    ##  9     9  2016                4.53
    ## 10    10  2016                0.62
    ## 11    11  2016                1.47
    ## 12    12  2016                2.32

``` r
precip_full <- bind_rows(precip_2016, precip_2017) %>%
  janitor::clean_names() %>%
  mutate(month = month.name[month])

precip_full
```

    ## # A tibble: 20 x 3
    ##    month      year total_precip_inches
    ##    <chr>     <dbl>               <dbl>
    ##  1 January    2016                3.23
    ##  2 February   2016                5.32
    ##  3 March      2016                2.24
    ##  4 April      2016                1.78
    ##  5 May        2016                5.19
    ##  6 June       2016                3.2 
    ##  7 July       2016                6.09
    ##  8 August     2016                3.96
    ##  9 September  2016                4.53
    ## 10 October    2016                0.62
    ## 11 November   2016                1.47
    ## 12 December   2016                2.32
    ## 13 January    2017                2.34
    ## 14 February   2017                1.46
    ## 15 March      2017                3.57
    ## 16 April      2017                3.99
    ## 17 May        2017                5.64
    ## 18 June       2017                1.4 
    ## 19 July       2017                7.09
    ## 20 August     2017                4.44

Mr. Trash Wheel cleans up garbage and debris from the Inner Harbor in Baltimore, MD. The dataset describes amounts and types of trash collected by dumpster and date. The dataset includes 215 observations, each representing a collected dumpster. The 14 variables include weight, volume, and types of trash, along with an estimate of homes powered by electricity from incinerated trash. From May 2014 to August 2017, Mr. Trash Wheel collected 704.44 tons of trash. Cigarette butts are a common item of pollution in the harbor. On average, 44500 cigarette butts are collected in each dumpster.

The combined precipitation dataset includes measurements from 20 months in 2016 and 2017. The 3 variables are month, year, and total precipation in inches. The total recorded precipitation in these two years was 69.88 inches. The average precipitation for each recorded month was 3.494 inches.

*For available data, what was the total precipitation in 2017?*

``` r
precip_full %>% 
  filter(year == 2017) %>% 
  summarise(total_precip_2017 = sum(total_precip_inches))
```

    ## # A tibble: 1 x 1
    ##   total_precip_2017
    ##               <dbl>
    ## 1              29.9

The total precipitation in 2017 was **29.93 inches**.

*What was the median number of sports balls in a dumpster in 2016?*

``` r
trash_wheel %>% 
  filter(year == 2016) %>% 
  summarise(median_balls = median(sports_balls))
```

    ## # A tibble: 1 x 1
    ##   median_balls
    ##          <int>
    ## 1           26

The median number of sports balls in a dumpster in 2016 was **26**.

Problem 3
=========

I will load and format the Behavioral Risk Factors Surveillance System for Selected Metropolitan Area Risk Trends (SMART) data from the p8105.datasets package.

``` r
data("brfss_smart2010")
brfss <- brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  select(-c(class, topic, question, sample_size, confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(excellent_or_vg = excellent + very_good) %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  separate(county, into = c("remove", "county"), sep = "- ") %>%
  select(year, state, county, poor, fair, good, very_good, excellent, excellent_or_vg)
  
brfss
```

    ## # A tibble: 2,125 x 9
    ##     year state coun~  poor  fair  good very_good excellent excellent_or_vg
    ##    <int> <chr> <chr> <dbl> <dbl> <dbl>     <dbl>     <dbl>           <dbl>
    ##  1  2002 AK    Anch~   5.9   8.6  23.8      33.7      27.9            61.6
    ##  2  2002 AL    Jeff~   5.9  12.1  32.7      30.9      18.5            49.4
    ##  3  2002 AR    Pula~   4.2  12.5  29.9      29.3      24.1            53.4
    ##  4  2002 AZ    Mari~   4.6  10.3  26.9      36.6      21.6            58.2
    ##  5  2002 AZ    Pima~   3.9   7.5  31.9      30.1      26.6            56.7
    ##  6  2002 CA    Los ~   4.5  14.3  28.7      29.8      22.7            52.5
    ##  7  2002 CO    Adam~   4.2  14.4  29        31.2      21.2            52.4
    ##  8  2002 CO    Arap~   2.1   8    29.3      35.2      25.5            60.7
    ##  9  2002 CO    Denv~   3    11.1  36.6      27.1      22.2            49.3
    ## 10  2002 CO    Jeff~   2.4  11.4  26.3      36.6      23.4            60  
    ## # ... with 2,115 more rows

For this question:

format the data to use appropriate variable names; focus on the “Overall Health” topic exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data\_value in the original dataset) create a new variable showing the proportion of responses that were “Excellent” or “Very Good” Using this dataset, do or answer the following:

How many unique locations are included in the dataset? Is every state represented? What state is observed the most? In 2002, what is the median of the “Excellent” response value? Make a histogram of “Excellent” response values in the year 2002. Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.
