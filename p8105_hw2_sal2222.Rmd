---
title: "p8105_hw2_sal2222"
author: "Stephen Lewandowski"
date: "October 4, 2018"
output: 
  github_document:
    toc: true
---

```{r setup, include = FALSE}

library(tidyverse)
library(readxl)
library(devtools)
library(p8105.datasets) #devtools::install_github("p8105/p8105.datasets")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

# Problem 1


First, I will read and clean the NYC Transit data.

```{r import subway data, message = FALSE}
nyc_subway_data <- read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, 
         entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE)) 
 
nyc_subway_data
  
```

This datase contains information related to each entrance and exit for each subway station in New York City, including the subway line, station name, location grid coordinates, routes served, entrance type, and ADA compliance status. My data cleaning steps so far have been to standardize variable names in "snake_case", select and retain my variables of interest, and to recode the entry variable from a character class with "YES" or "NO" values to a logical class with "TRUE" or "FALSE" values. My resulting dataset has **`r nrow(nyc_subway_data)` rows** and **`r ncol(nyc_subway_data)` columns**. These data are **not tidy** at this stage. The multiple columns for route numbers (routes 1 through 11) represent values themselves rather than a variable name.    


I will answer specific questions using these data.


*How many distinct stations are there?*

There are **`r nrow(distinct(nyc_subway_data, line, station_name))`** distinct stations, identified by both line and station name.


*How many stations are ADA compliant?*

```{r ADA compliant stations}
nyc_subway_data %>% 
  filter(ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```
Of the `r nrow(distinct(nyc_subway_data, line, station_name))` distinct stations, **84** have at least one ADA compliant entrance or exit. 


*What proportion of station entrances / exits without vending allow entrance?*

```{r entry without vending}
{
  nyc_subway_data %>% 
  filter(vending == "NO") %>%
  filter(entry == TRUE) %>%  
  nrow()
} /
{
  nyc_subway_data %>% 
  filter(vending == "NO") %>%
  nrow()
}
```
**0.37.7** (37.7%) of station entrances / exits without vending allow entrance. There are 183 entrances / exits without vending, and 69 of these allow entry.


I will now reformat the data so that route number and route name are distinct variables. 

```{r reformat routes}
nyc_subway_data <- nyc_subway_data %>% 
  gather(key = route_number, value = route_name, route1:route11) 

nyc_subway_data
```

*How many distinct stations serve the A train?*
```{r distinct stations A train}
nyc_subway_data %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```
**60** distinct stations serve the A train. 


*How many are ADA compliant?*
```{r ADA compliant A train}
nyc_subway_data %>% 
  filter(ada == TRUE) %>%  
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```
Of the 60 stations that serve the A train, **17** have at least one ADA compliant entry or exit.



# Problem 2

I will read and clean data from Mr. Trash Wheel in Baltimore Harbor.

```{r import trash wheel data}
trash_wheel <- read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
               sheet = "Mr. Trash Wheel", range =  cell_cols("A:N"), 
               col_names = TRUE, trim_ws = TRUE, skip = 1) %>% 
  janitor::clean_names() %>% 
  rename(dumpster_number = dumpster) %>% 
  filter(!is.na(dumpster_number)) %>% 
  filter(!(month == "Grand Total")) %>% 
  mutate(sports_balls = round(sports_balls, 0)) %>% 
  mutate(sports_balls = as.integer(sports_balls))

trash_wheel

```


Next, I will read, clean, and combine precipitation data for 2016 and 2017. 

```{r import Baltimore precip data}
precip_2017 <- read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
               sheet = "2017 Precipitation", range =  "A2:B14", 
               col_names = TRUE, trim_ws = TRUE) %>% 
  janitor::clean_names() %>%
  rename(total_precip_inches = total) %>% 
  filter(!is.na(total_precip_inches)) %>% 
  mutate(year = 2017) %>% 
  select(month, year, total_precip_inches)

precip_2017

precip_2016 <- read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
               sheet = "2016 Precipitation", range =  "A2:B14", 
               col_names = TRUE, trim_ws = TRUE) %>% 
  janitor::clean_names() %>%
  rename(total_precip_inches = total) %>% 
  filter(!is.na(total_precip_inches)) %>% 
  mutate(year = 2016) %>% 
  select(month, year, total_precip_inches)

precip_2016

```

```{r combine precip data}
precip_full <- bind_rows(precip_2016, precip_2017) %>%
  janitor::clean_names() %>%
  mutate(month = month.name[month])

precip_full
```


Mr. Trash Wheel cleans up garbage and debris from the Inner Harbor in Baltimore, MD. The dataset describes amounts and types of trash collected by dumpster and date. The dataset includes `r nrow(trash_wheel)` observations, each representing a collected dumpster. The `r ncol(trash_wheel)` variables include weight, volume, and types of trash, along with an estimate of homes powered by electricity from incinerated trash. From May 2014 to August 2017, Mr. Trash Wheel collected `r   sum(trash_wheel$weight_tons)` tons of trash. Cigarette butts are a common item of pollution in the harbor. On average, `r as.integer(mean(trash_wheel$cigarette_butts))` cigarette butts are collected in each dumpster.       


The combined precipitation dataset includes measurements from `r nrow(precip_full)` months in 2016 and 2017. The `r ncol(precip_full)` variables are month, year, and total precipation in inches. The total recorded precipitation in these two years was `r sum(precip_full$total_precip_inches)` inches. The average precipitation for each recorded month was `r mean(precip_full$total_precip_inches)` inches.  


*For available data, what was the total precipitation in 2017?*

```{r total precip 2017}
precip_full %>% 
  filter(year == 2017) %>% 
  summarise(total_precip_2017 = sum(total_precip_inches))
```
The total precipitation in 2017 was **29.93 inches**.

*What was the median number of sports balls in a dumpster in 2016?*
```{r median balls 2016}
trash_wheel %>% 
  filter(year == 2016) %>% 
  summarise(median_balls = median(sports_balls))
```
The median number of sports balls in a dumpster in 2016 was **26**.


# Problem 3

I will load and format the Behavioral Risk Factors Surveillance System (BRFSS) for Selected Metropolitan Area Risk Trends (SMART) data from the p8105.datasets package.

```{r load BRFSS}

data("brfss_smart2010")
brfss <- brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  select(-c(class, topic, question, sample_size, confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(excellent_or_vg = excellent + very_good) %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  separate(county, into = c("remove", "county"), sep = "- ") %>%
  select(year, state, county, poor, fair, good, very_good, excellent, excellent_or_vg)
  
brfss
   
```


I will answer questions using this reformatted BRFSS dataset.

*How many unique locations are included in the dataset? Is every state represented? What state is observed the most?*

```{r unique locations}
brfss %>% 
  distinct(state, county) %>% 
  nrow()

brfss %>% 
  distinct(state) %>% 
  nrow()

brfss %>% 
  count(state, sort = TRUE) 
```
There are **404** distinct county-level locations included in this dataset.

Yes, all 50 states and the District of Columbia (**51 total**) are represented.

**New Jersey** is the most observed state with **146** observations.



*In 2002, what is the median of the “Excellent” response value?*

```{r brfss median 2002}
# Inspect data for missing values
brfss %>% 
  filter(year == 2002) %>% 
   skimr::skim(excellent)

brfss %>% 
  filter(year == 2002) %>% 
  summarise(median = median(excellent, na.rm = TRUE))

```

Not considering 2 missing responses in the category, the median of the “Excellent” response value is **23.6**. 



*Make a histogram of “Excellent” response values in the year 2002.*

Below is a histogram of “Excellent” response values in the year 2002.

```{r bfrss histogram, warning = FALSE, message = FALSE}
brfss %>% 
  filter(year == 2002) %>%
  ggplot(aes(x = excellent)) + 
  geom_histogram() +
  labs(
    title = "Excellent response values in 2002",
    x = "Proportion of excellent response values",
    caption = "Data from BFRSS SMART 2010" 
  ) 
  
```


*Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.*

Below is a scatterplot with the proportion of “Excellent” response values in New York County and Queens County in each year from 2002 to 2010.

```{r brfss ny scatterplot}

brfss %>%
  filter(county == "New York County" | county == "Queens County") %>%
  ggplot(aes(x = year, y = excellent, color = county)) + 
  geom_point(size = 2) +
  labs(
    title = "Excellent response values",
    x = "Year",
    y = "Proportion of excellent responses",
    caption = "Data from BFRSS SMART 2010"
  )
 
```

